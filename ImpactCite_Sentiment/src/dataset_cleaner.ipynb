{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from Levenshtein import distance\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(liste):\n",
    "    # put in dict\n",
    "    dico = dict()\n",
    "\n",
    "    for i in tqdm(liste):\n",
    "        dico[i] = dico.get(i, 0) + 1\n",
    "\n",
    "    output_dict = {}    \n",
    "    for i in tqdm(dico):\n",
    "        if dico[i] > 1: # for dico's element where value >= 2\n",
    "            output_dict[i] = [a+1 for a, b in enumerate(liste) if b == i]\n",
    "\n",
    "    return output_dict, dico\n",
    "\n",
    "\n",
    "def load_citation_sentiment_corpus(filepath):\n",
    "    texts = []\n",
    "    polarities = []\n",
    "    n_num = 0\n",
    "    o_num = 0\n",
    "    p_num = 0\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # look for invalid lines\n",
    "            if (len(line) is 0):\n",
    "                continue\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            # divide the line into columns\n",
    "            pieces = line.split('\\t')\n",
    "            if (len(pieces) != 4):\n",
    "                print(\"Warning: incorrect number of fields in the data file for line:\", line)\n",
    "                continue\n",
    "            \n",
    "            text = pieces[3]\n",
    "            # remove start/end quotes\n",
    "            text = text[1:len(text) - 1]\n",
    "            \n",
    "            # create the labels and count them\n",
    "            if pieces[2] is 'n':\n",
    "                n_num += 1\n",
    "                polarities.append(0)\n",
    "            if pieces[2] is 'o':\n",
    "                o_num += 1\n",
    "                polarities.append(1)\n",
    "            if pieces[2] is 'p':\n",
    "                p_num += 1\n",
    "                polarities.append(2)\n",
    "            texts.append(text)\n",
    "\n",
    "    print(\"o_num= \", o_num)\n",
    "    print(\"p_num= \", p_num)\n",
    "    print(\"n_num= \", n_num)\n",
    "\n",
    "    return np.asarray(texts), np.asarray(polarities)\n",
    "\n",
    "\n",
    "def add_to_dict(dictonary,key,value):   \n",
    "    if key in dictonary:\n",
    "        dictonary[key].add(value)\n",
    "    else:\n",
    "        dictonary[key] = {value}\n",
    "        \n",
    "def prepare_labels_dict(text_list,labels):\n",
    "    d1 = defaultdict(set)\n",
    "    # create data + label dict\n",
    "    for text,label in tqdm(zip(text_list,labels)):\n",
    "        add_to_dict(d1,text,label)\n",
    "\n",
    "    #find all the text with more then 1 labels assigned to it.\n",
    "    key_list=[]\n",
    "    for i in d1:\n",
    "        if len(d1[i])>1:\n",
    "            key_list.append(i)\n",
    "\n",
    "    return d1,key_list\n",
    "\n",
    "def check_multi_label(text_list,label_dict):\n",
    "    for text in text_list:\n",
    "        if len(label_dict[text])>1:\n",
    "            print(\"ERROR\", text)\n",
    "            return \n",
    "    print(\"No Multi label text found\")"
   ]
  },
  {
   "source": [
    "Reads the complete corpus and counts the labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_num=  7627\n",
      "p_num=  829\n",
      "n_num=  280\n"
     ]
    }
   ],
   "source": [
    "text_list,labels_list=load_citation_sentiment_corpus('../data/complete_corpus.txt')"
   ]
  },
  {
   "source": [
    "Cleans the corpus by removing all incorrect labeled instances."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8736/8736 [00:00<00:00, 14835.94it/s]\n",
      "100%|██████████| 8059/8059 [05:40<00:00, 23.69it/s] \n",
      "8736it [00:00, 13997.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Multi label text found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# finds duplicates\n",
    "duplicates_dic,complete_count_dict=find_duplicates(text_list)\n",
    "# prepare the label dictionary\n",
    "complete_labels_dict, multi_label_text_list=prepare_labels_dict(text_list,labels_list)\n",
    "# setup the required lists of data and label dicts\n",
    "duplicate_texts=list(duplicates_dic.keys())\n",
    "complete_texts=list(complete_count_dict.keys())\n",
    "duplicates_removed=list(set(complete_texts).intersection(multi_label_text_list))\n",
    "final_texts_list=list(set(complete_texts)^set(multi_label_text_list))\n",
    "\n",
    "if len(duplicates_removed)!= len(multi_label_text_list):\n",
    "    print(\"ERROR! Something is wrong!! The number of removed samples should be equal to the number of samples with multiple labels.\")\n",
    "# check if a text has multiple labels\n",
    "check_multi_label(final_texts_list,complete_labels_dict)\n",
    "# create final label list\n",
    "final_labels_list=[]\n",
    "for text in final_texts_list:\n",
    "    if len(complete_labels_dict[text])==1:\n",
    "        label_set=complete_labels_dict[text]\n",
    "        label=next(iter(label_set))\n",
    "        final_labels_list.append(label)\n",
    "    else:\n",
    "        print(\"ERROR Muilti label\",text,complete_labels_dict[text])"
   ]
  },
  {
   "source": [
    "Create the duplicates handling file that covers information about the removed text samples and their labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_string(label_set):\n",
    "    # creates the label string by converting the label set to the corresponding string.\n",
    "    # used to see the different labels for each sample.\n",
    "    result=''\n",
    "    for label in label_set:\n",
    "        if label == 0:\n",
    "            result=result+' NEGATIVE '\n",
    "        elif label ==1:\n",
    "            result=result+' NEUTRAL '\n",
    "        else:\n",
    "            result=result+' POSITIVE '\n",
    "\n",
    "    return result\n",
    "\n",
    "# collects the text for the duplicate handling file          \n",
    "text_to_write='\\n\\n'\n",
    "\n",
    "text_to_write=text_to_write+'========DUPLICATES REMOVED========\\n\\n'            \n",
    "for text in duplicates_removed:\n",
    "    text_to_write=text_to_write+text+'\\n LABELS:'\n",
    "    label_set=complete_labels_dict[text];\n",
    "    text_to_write=text_to_write+get_labels_string(label_set)+'\\n\\n\\n'\n",
    "\n",
    "\n",
    "text_to_write=text_to_write+'==========ALL DUPLICATES=========\\n'\n",
    "for text in duplicate_texts:\n",
    "    text_to_write=text_to_write+text+'\\n LABELS:'\n",
    "    label_set=complete_labels_dict[text];\n",
    "    text_to_write=text_to_write+get_labels_string(label_set)+'\\n\\n\\n'\n",
    "    \n",
    "\n",
    "text_to_write=text_to_write+'==========COMPLETE DATASET AFTER HANDLING DUPLICATES=========\\n'\n",
    "for text in final_texts_list:\n",
    "    text_to_write=text_to_write+text+'\\n LABELS:'\n",
    "    label_set=complete_labels_dict[text];\n",
    "    text_to_write=text_to_write+get_labels_string(label_set)+'\\n\\n\\n'\n",
    "    \n",
    "# save the duplicate handling files    \n",
    "text_file = open(\"Duplicates_handling.txt\", \"w\")\n",
    "n = text_file.write(text_to_write)\n",
    "text_file.close()"
   ]
  },
  {
   "source": [
    "Statistics for the data that is left."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length after removing duplicates 7980\n",
      "Labels length after removing duplicates 7980\n"
     ]
    }
   ],
   "source": [
    "print(\"Text length after removing duplicates\",len(final_texts_list))\n",
    "print(\"Labels length after removing duplicates\",len(final_labels_list))\n",
    "\n",
    "if(len(final_texts_list)!=len(final_labels_list)):\n",
    "    print('Something is not right check again! The number of labels and data samples is not the same.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_letter(label):\n",
    "    # convert the labels to the corresponding character.\n",
    "    if label == 0:\n",
    "        return \"n\"+\"\\t\"\n",
    "    elif label ==1:\n",
    "        return \"o\"+\"\\t\"\n",
    "    elif label ==2:\n",
    "        return \"p\"+\"\\t\"\n",
    "    else:\n",
    "        print(\"CONTROL SHOULD NEVER COME HERE!\")\n",
    "\n",
    "def write_data_txt(text_list,test=False,prefix=''):\n",
    "    # method to write the output files that include additional columns to process them using XLNet with the imdb processor\n",
    "    file_name=\"\"\n",
    "    if test==True:\n",
    "        # test folds\n",
    "        print('For Test data with',prefix,)\n",
    "        file_name='../data/output/'+prefix+'test.txt'\n",
    "    else:\n",
    "        # train data\n",
    "        print('For Train data with',prefix,)\n",
    "        file_name='../data/output/'+prefix+'train.txt'\n",
    "    # count instances\n",
    "    negative_count = 0\n",
    "    neutral_count = 0\n",
    "    positive_count = 0\n",
    "    text_to_write=''\n",
    "    for line in text_list:\n",
    "        # add dummy columns\n",
    "        text_to_write=text_to_write+\"AA\"+\"\\t\"+\"AA\"+\"\\t\"\n",
    "        label=''\n",
    "        if len(complete_labels_dict[line])==1:\n",
    "            label_set=complete_labels_dict[line]\n",
    "            label=next(iter(label_set))\n",
    "            #print(label)\n",
    "            if label == 0:\n",
    "                negative_count=negative_count+1\n",
    "            elif label ==1:\n",
    "                neutral_count=neutral_count+1\n",
    "            elif label ==2:\n",
    "                positive_count=positive_count+1\n",
    "            else:\n",
    "                print(\"CONTROL SHOULD NEVER COME HERE! Wrong label detected\")           \n",
    "        else:\n",
    "            print(\"ERROR! THIS SHOULD NOT HAPPEN! Wrong number of labels e.g. multi label.\")\n",
    "        text_to_write=text_to_write+get_labels_letter(label)+line+\"\\n\"\n",
    "    \n",
    "    # statistics\n",
    "    print(\"Number of POSITIVE examples:\",positive_count)\n",
    "    print(\"Number of NEGATIVE examples:\",negative_count)\n",
    "    print(\"Number of NEUTRAL examples:\",neutral_count)\n",
    "    \n",
    "    # save the fold\n",
    "    text_file = open(file_name, \"w\")\n",
    "    n = text_file.write(text_to_write)\n",
    "    text_file.close()"
   ]
  },
  {
   "source": [
    "Complete data computed using cosine similarity."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train data with cosine\n",
      "Number of POSITIVE examples: 728\n",
      "Number of NEGATIVE examples: 253\n",
      "Number of NEUTRAL examples: 6999\n"
     ]
    }
   ],
   "source": [
    "write_data_txt(final_texts_list,prefix='cosine')"
   ]
  },
  {
   "source": [
    "Compute the 10 folds for cross validation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "For Train data with Fold_1\n",
      "Number of POSITIVE examples: 641\n",
      "Number of NEGATIVE examples: 228\n",
      "Number of NEUTRAL examples: 6313\n",
      "For Test data with Fold_1\n",
      "Number of POSITIVE examples: 87\n",
      "Number of NEGATIVE examples: 25\n",
      "Number of NEUTRAL examples: 686\n",
      "\n",
      "\n",
      "For Train data with Fold_2\n",
      "Number of POSITIVE examples: 651\n",
      "Number of NEGATIVE examples: 234\n",
      "Number of NEUTRAL examples: 6297\n",
      "For Test data with Fold_2\n",
      "Number of POSITIVE examples: 77\n",
      "Number of NEGATIVE examples: 19\n",
      "Number of NEUTRAL examples: 702\n",
      "\n",
      "\n",
      "For Train data with Fold_3\n",
      "Number of POSITIVE examples: 635\n",
      "Number of NEGATIVE examples: 231\n",
      "Number of NEUTRAL examples: 6316\n",
      "For Test data with Fold_3\n",
      "Number of POSITIVE examples: 93\n",
      "Number of NEGATIVE examples: 22\n",
      "Number of NEUTRAL examples: 683\n",
      "\n",
      "\n",
      "For Train data with Fold_4\n",
      "Number of POSITIVE examples: 674\n",
      "Number of NEGATIVE examples: 221\n",
      "Number of NEUTRAL examples: 6287\n",
      "For Test data with Fold_4\n",
      "Number of POSITIVE examples: 54\n",
      "Number of NEGATIVE examples: 32\n",
      "Number of NEUTRAL examples: 712\n",
      "\n",
      "\n",
      "For Train data with Fold_5\n",
      "Number of POSITIVE examples: 651\n",
      "Number of NEGATIVE examples: 231\n",
      "Number of NEUTRAL examples: 6300\n",
      "For Test data with Fold_5\n",
      "Number of POSITIVE examples: 77\n",
      "Number of NEGATIVE examples: 22\n",
      "Number of NEUTRAL examples: 699\n",
      "\n",
      "\n",
      "For Train data with Fold_6\n",
      "Number of POSITIVE examples: 669\n",
      "Number of NEGATIVE examples: 222\n",
      "Number of NEUTRAL examples: 6291\n",
      "For Test data with Fold_6\n",
      "Number of POSITIVE examples: 59\n",
      "Number of NEGATIVE examples: 31\n",
      "Number of NEUTRAL examples: 708\n",
      "\n",
      "\n",
      "For Train data with Fold_7\n",
      "Number of POSITIVE examples: 658\n",
      "Number of NEGATIVE examples: 222\n",
      "Number of NEUTRAL examples: 6302\n",
      "For Test data with Fold_7\n",
      "Number of POSITIVE examples: 70\n",
      "Number of NEGATIVE examples: 31\n",
      "Number of NEUTRAL examples: 697\n",
      "\n",
      "\n",
      "For Train data with Fold_8\n",
      "Number of POSITIVE examples: 653\n",
      "Number of NEGATIVE examples: 229\n",
      "Number of NEUTRAL examples: 6300\n",
      "For Test data with Fold_8\n",
      "Number of POSITIVE examples: 75\n",
      "Number of NEGATIVE examples: 24\n",
      "Number of NEUTRAL examples: 699\n",
      "\n",
      "\n",
      "For Train data with Fold_9\n",
      "Number of POSITIVE examples: 666\n",
      "Number of NEGATIVE examples: 231\n",
      "Number of NEUTRAL examples: 6285\n",
      "For Test data with Fold_9\n",
      "Number of POSITIVE examples: 62\n",
      "Number of NEGATIVE examples: 22\n",
      "Number of NEUTRAL examples: 714\n",
      "\n",
      "\n",
      "For Train data with Fold_10\n",
      "Number of POSITIVE examples: 654\n",
      "Number of NEGATIVE examples: 228\n",
      "Number of NEUTRAL examples: 6300\n",
      "For Test data with Fold_10\n",
      "Number of POSITIVE examples: 74\n",
      "Number of NEGATIVE examples: 25\n",
      "Number of NEUTRAL examples: 699\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split into ten folds.\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(final_labels_list)\n",
    "final_texts_list=np.array(final_texts_list)\n",
    "print(kf)\n",
    "count=1\n",
    "for train_index, test_index in kf.split(final_texts_list):\n",
    "    # split into trian and test\n",
    "    X_train, X_test = final_texts_list[train_index], final_texts_list[test_index]\n",
    "    file_name='Fold_'+str(count)\n",
    "    count+=1\n",
    "    # process fold\n",
    "    write_data_txt(X_train,prefix=file_name)\n",
    "    write_data_txt(X_test,test=True,prefix=file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}